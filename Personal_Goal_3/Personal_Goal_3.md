### The background 



---

### Methodology and data sourced used 



---


### Details about the implementation 

The implementation is provided in two Jupyter Notebooks: 

- **Data_Analysis.ipynb**




- **DataPreperation.ipynb**



---

### Results 

The final output of the pipeline is a clean and consistent dataset 
that can be directly used for exploratory analysis or modeling.

Compared to my initial approach, the structured pipeline reduced
data preparation time and improved code readability and reusability.
Summary statistics included in the notebook demonstrate the quality of the processed data.

---

### Conclusion 

The results show that selection the data source, either from a website or from a service by using API key can play a big role in data acquisition, preperation and wrangling. It can improve or degrade the efficiency and data quality.

This learning goal was acchieved as, I am able now to collect data from different sources. Clean and transform the retrieved data in order to be ready for further analysis. Finally to wrap all the above in reusable and organized pipelines.